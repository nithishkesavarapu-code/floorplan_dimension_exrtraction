{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8UsKtifok37CG6vTZVtfI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nithishkesavarapu-code/floorplan_dimension_exrtraction/blob/main/assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install PyMuPDF pdfplumber regex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpzxzE2XZZPD",
        "outputId": "67291bff-43dc-4a38-a377-09cd7b131dd9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (2024.11.6)\n",
            "Collecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\n",
            "Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, PyMuPDF, pdfminer.six, pdfplumber\n",
            "Successfully installed PyMuPDF-1.26.4 pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import os\n",
        "import regex as re\n",
        "import math\n",
        "import json\n",
        "from typing import List, Dict, Any"
      ],
      "metadata": {
        "id": "vnP5ZW_Z7JR5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DIMENSION_REGEX_RAW = r\"\"\"\n",
        "    \\b\n",
        "    (?:\n",
        "        # Pattern A: Feet and Inches (e.g., 2' 6 1/2\", 3'-6\")\n",
        "        (?P<feet>\\d+)\\s*['\\u2032][\\s-]* # Feet value followed by ' or prime symbol\n",
        "        (?:\n",
        "            (?P<whole_inches>\\d*)[\\s-]* # Optional whole inches (can be 0)\n",
        "            (?:(?P<num>\\d+)[/](?P<den>\\d+))?            # Optional fraction (e.g., 1/2)\n",
        "        )?\n",
        "        \\s*[\"\\u2033]?                                   # Optional inches symbol or double prime symbol\n",
        "    )\n",
        "    |\n",
        "    (?:\n",
        "        # Pattern B: Inches Only (e.g., 25\", 34 1/2\")\n",
        "        (?P<inches_only>\\d+)[\\s-]* # Whole inches value\n",
        "        (?:(?P<num_only>\\d+)[/](?P<den_only>\\d+))?      # Optional fraction\n",
        "        \\s*[\"\\u2033]                                    # MUST have an inches symbol\n",
        "    )\n",
        "    |\n",
        "    (?:\n",
        "        # Pattern C: Simple Feet Only (e.g., 10')\n",
        "        (?P<feet_only>\\d+)\\s*['\\u2032]\n",
        "    )\n",
        "    \\b\n",
        "    |\n",
        "    # NEW Pattern D: Dimensions separated by 'x' (e.g., 14'x8', 9'3\"x10'3\")\n",
        "    # This is common in floorplans and needs special handling for accurate bbox in a moment.\n",
        "    # For now, we capture the whole string.\n",
        "    (?P<room_dim>\n",
        "        \\d+['\\u2032] (?: \\d+[\"\\u2033] )? # First dimension (e.g., 14' or 9'3\")\n",
        "        \\s*[xX]\\s* # Separator 'x'\n",
        "        \\d+['\\u2032] (?: \\d+[\"\\u2033] )? # Second dimension (e.g., 8' or 10'3\")\n",
        "    )\n",
        "\"\"\"\n",
        "DIMENSION_REGEX = re.compile(DIMENSION_REGEX_RAW, re.VERBOSE | re.IGNORECASE)"
      ],
      "metadata": {
        "id": "Fa8yQYfwm9Yj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CODE_REGEX = re.compile(r\"\"\"\n",
        "    \\b                      # Word boundary\n",
        "    [A-Z]{2,}               # Two or more uppercase letters (e.g., DB, SB)\n",
        "    [0-9]{2,}               # Two or more digits (e.g., 24, 42)\n",
        "    [A-Z0-9]* # Optional alphanumeric suffix (e.g., FH)\n",
        "    \\b                      # Word boundary\n",
        "\"\"\", re.VERBOSE)"
      ],
      "metadata": {
        "id": "W67xrdqZwZQC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_inches(match: re.Match) -> float:\n",
        "    \"\"\"Parses a dimension match object and converts the value to a float in inches.\"\"\"\n",
        "    total_inches = 0.0\n",
        "    group_dict = match.groupdict()\n",
        "\n",
        "    # Helper to convert a single dimension string (e.g., \"9'3\\\"\")\n",
        "    def simple_string_to_inches(dim_str: str) -> float:\n",
        "        f = 0.0\n",
        "        i = 0.0\n",
        "\n",
        "        # Extract feet (e.g., 9' or 14')\n",
        "        feet_match = re.search(r\"(\\d+)\\s*['\\u2032]\", dim_str)\n",
        "        if feet_match:\n",
        "            f = float(feet_match.group(1))\n",
        "\n",
        "        # Extract inches (e.g., 3\")\n",
        "        inches_match = re.search(r\"(\\d+)\\s*[\\\"\\u2033]\", dim_str)\n",
        "        if inches_match:\n",
        "            i = float(inches_match.group(1))\n",
        "\n",
        "        return (f * 12.0) + i\n",
        "\n",
        "    # Handle the 'x' separated room dimensions\n",
        "    if group_dict.get('room_dim'):\n",
        "        try:\n",
        "            # Match the first dimension part\n",
        "            # Adjusted regex to handle unicode/ascii prime/double prime symbols\n",
        "            first_dim_match = re.match(r\"(?P<dim_a>\\d+['\\u2032] (?:\\d+[\\\"\\u2033])?)\\s*[xX]\", group_dict['room_dim'])\n",
        "            if first_dim_match:\n",
        "                # Use the helper function to convert the first dimension part\n",
        "                return simple_string_to_inches(first_dim_match.group('dim_a').strip())\n",
        "            return 0.0\n",
        "        except Exception:\n",
        "            return 0.0\n",
        "\n",
        "    # Existing logic for single dimensions\n",
        "    try:\n",
        "        # Handle Feet (Pattern A or C)\n",
        "        feet_str = group_dict.get('feet') or group_dict.get('feet_only')\n",
        "        if feet_str:\n",
        "            total_inches += float(feet_str) * 12.0\n",
        "\n",
        "        # Handle Inches and Fractions (Pattern A: with feet)\n",
        "        whole_inches_str = group_dict.get('whole_inches')\n",
        "        num_str = group_dict.get('num')\n",
        "        den_str = group_dict.get('den')\n",
        "\n",
        "        if match.group('feet'):\n",
        "            if whole_inches_str and whole_inches_str.strip():\n",
        "                total_inches += float(whole_inches_str)\n",
        "            if num_str and den_str:\n",
        "                total_inches += float(num_str) / float(den_str)\n",
        "\n",
        "        # Handle Inches Only (Pattern B: no feet)\n",
        "        inches_only_str = group_dict.get('inches_only')\n",
        "        num_only_str = group_dict.get('num_only')\n",
        "        den_only_str = group_dict.get('den_only')\n",
        "\n",
        "        if inches_only_str:\n",
        "            total_inches += float(inches_only_str)\n",
        "            if num_only_str and den_only_str:\n",
        "                total_inches += float(num_only_str) / float(den_only_str)\n",
        "\n",
        "    except (ValueError, ZeroDivisionError, TypeError) as e:\n",
        "        print(f\"Error converting dimension '{match.group(0)}': {e}\")\n",
        "        return 0.0\n",
        "\n",
        "    return round(total_inches, 4)"
      ],
      "metadata": {
        "id": "ZtqDEYGqJDRa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bbox_for_span(words: List[Dict[str, Any]], start_index: int, end_index: int) -> List[float]:\n",
        "    \"\"\"\n",
        "    Calculates the combined bounding box [x0, y0, x1, y1] for a sequence of words.\n",
        "    \"\"\"\n",
        "    if start_index >= len(words) or end_index >= len(words):\n",
        "        return [0.0, 0.0, 0.0, 0.0]\n",
        "\n",
        "    start_word = words[start_index]\n",
        "    end_word = words[end_index]\n",
        "\n",
        "    # Combine the top-left of the first word with the bottom-right of the last word\n",
        "    return [\n",
        "        start_word['x0'],  # Smallest X\n",
        "        start_word['top'], # Smallest Y (top)\n",
        "        end_word['x1'],    # Largest X\n",
        "        end_word['bottom'] # Largest Y (bottom)\n",
        "    ]"
      ],
      "metadata": {
        "id": "8LAnNCRnJEvr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_pdf_and_generate_json(pdf_path: str, output_json_path: str):\n",
        "    \"\"\"\n",
        "    Main pipeline function to extract data, bounding boxes, and generate the final JSON file.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(pdf_path):\n",
        "        print(f\"Error: The file at {pdf_path} was not found. Cannot proceed.\")\n",
        "        return []\n",
        "\n",
        "    final_results = []\n",
        "\n",
        "    print(\"Starting PDF processing for Bbox extraction and JSON generation...\")\n",
        "\n",
        "    try:\n",
        "        with pdfplumber.open(pdf_path) as pdf:\n",
        "            # Iterate through each page of the PDF\n",
        "            for page_num, page in enumerate(pdf.pages, 1):\n",
        "                page_data = {\n",
        "                    \"page\": page_num,\n",
        "                    \"dimensions\": [],\n",
        "                    \"codes\": []\n",
        "                }\n",
        "\n",
        "                # Use extract_words to get text with coordinates (bbox)\n",
        "                words = page.extract_words(x_tolerance=3, y_tolerance=2)\n",
        "\n",
        "                # 1. Create a raw text string and an index map\n",
        "                raw_text_list = []\n",
        "                index_to_word_map = {}\n",
        "\n",
        "                current_char_index = 0\n",
        "                for i, word in enumerate(words):\n",
        "                    index_to_word_map[current_char_index] = i\n",
        "                    raw_text_list.append(word['text'])\n",
        "                    current_char_index += len(word['text'])\n",
        "\n",
        "                    if i < len(words) - 1:\n",
        "                        raw_text_list.append(' ')\n",
        "                        current_char_index += 1\n",
        "\n",
        "                page_text = \"\".join(raw_text_list)\n",
        "\n",
        "                # --- A. DIMENSION EXTRACTION ---\n",
        "                print(f\"  Processing page {page_num} for dimensions...\")\n",
        "\n",
        "                for match in DIMENSION_REGEX.finditer(page_text):\n",
        "                    raw_dim = match.group(0).strip()\n",
        "                    inches = convert_to_inches(match)\n",
        "\n",
        "                    # Find start word index\n",
        "                    start_char_index = match.start()\n",
        "                    start_word_index = None\n",
        "                    for i in range(start_char_index, -1, -1):\n",
        "                        if i in index_to_word_map:\n",
        "                            start_word_index = index_to_word_map[i]\n",
        "                            break\n",
        "\n",
        "                    # Find end word index\n",
        "                    current_match_end_word_index = start_word_index\n",
        "                    current_span_length = 0\n",
        "\n",
        "                    if start_word_index is not None:\n",
        "                        for i in range(start_word_index, len(words)):\n",
        "                            word_len = len(words[i]['text'])\n",
        "                            current_span_length += word_len\n",
        "\n",
        "                            # Check if the combined length of words covers the raw dimension string length (ignoring spaces)\n",
        "                            if current_span_length >= len(raw_dim.replace(\" \", \"\").replace(\"'\",\"\").replace('\"','')):\n",
        "                                current_match_end_word_index = i\n",
        "                                break\n",
        "\n",
        "                            current_span_length += 1 # Account for the space between words\n",
        "\n",
        "                    bbox = [0.0, 0.0, 0.0, 0.0]\n",
        "                    if start_word_index is not None and current_match_end_word_index is not None:\n",
        "                        bbox = get_bbox_for_span(words, start_word_index, current_match_end_word_index)\n",
        "\n",
        "                    page_data[\"dimensions\"].append({\n",
        "                        \"raw\": raw_dim,\n",
        "                        \"inches\": inches,\n",
        "                        \"bbox\": [round(c, 2) for c in bbox]\n",
        "                    })\n",
        "\n",
        "                # --- B. CODE EXTRACTION ---\n",
        "                print(f\"  Processing page {page_num} for codes...\")\n",
        "\n",
        "                for match in CODE_REGEX.finditer(page_text):\n",
        "                    code = match.group(0).strip()\n",
        "\n",
        "                    start_char_index = match.start()\n",
        "                    start_word_index = None\n",
        "                    for i in range(start_char_index, -1, -1):\n",
        "                        if i in index_to_word_map:\n",
        "                            start_word_index = index_to_word_map[i]\n",
        "                            break\n",
        "\n",
        "                    code_bbox = [0.0, 0.0, 0.0, 0.0]\n",
        "                    if start_word_index is not None:\n",
        "                        code_bbox = get_bbox_for_span(words, start_word_index, start_word_index)\n",
        "                        page_data[\"codes\"].append({\n",
        "                            \"code\": code,\n",
        "                            \"bbox\": [round(c, 2) for c in code_bbox]\n",
        "                        })\n",
        "                    else:\n",
        "                         page_data[\"codes\"].append({\"code\": code, \"bbox\": [0.0, 0.0, 0.0, 0.0]})\n",
        "\n",
        "\n",
        "                final_results.append(page_data)\n",
        "\n",
        "        # Write results to the JSON file\n",
        "        with open(output_json_path, 'w') as f:\n",
        "            json.dump(final_results, f, indent=4)\n",
        "\n",
        "        print(f\"\\nSuccessfully extracted data for {len(final_results)} pages and saved to '{output_json_path}'\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"A fatal error occurred during PDF processing: {e}\")\n",
        "\n",
        "    return final_results"
      ],
      "metadata": {
        "id": "1JI5rOAEJM-V"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    pdf_file_path = \"/content/sample_data/floorplan.pdf\"\n",
        "    output_json_file = \"output.json\"\n",
        "\n",
        "    # 1. Run the main pipeline to extract data and generate JSON\n",
        "    extracted_data = process_pdf_and_generate_json(pdf_file_path, output_json_file)\n",
        "\n",
        "    # Print summary (kept for verification as per previous steps)\n",
        "    if extracted_data:\n",
        "        print(\"\\n--- SUMMARY OF FIRST PAGE (FOR CONSOLE VERIFICATION) ---\")\n",
        "        first_page = extracted_data[0]\n",
        "        print(f\"Page: {first_page['page']}\")\n",
        "\n",
        "        print(\"\\nDimensions Found (First 5):\")\n",
        "        for dim in first_page[\"dimensions\"][:5]:\n",
        "            print(f\"  Raw: {dim['raw']}, Inches: {dim['inches']:.2f}, Bbox: {dim['bbox']}\")\n",
        "\n",
        "        print(\"\\nCodes Found:\")\n",
        "        if first_page[\"codes\"]:\n",
        "            for code in first_page[\"codes\"]:\n",
        "                print(f\"  Code: {code['code']}, Bbox: {code['bbox']}\")\n",
        "        else:\n",
        "            print(\"  No cabinet/appliance codes found on this page.\")\n",
        "\n",
        "        print(\"----------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1U7COU0VT07",
        "outputId": "5a7a1533-9210-44db-d29f-71d478879d64"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting PDF processing for Bbox extraction and JSON generation...\n",
            "  Processing page 1 for dimensions...\n",
            "  Processing page 1 for codes...\n",
            "\n",
            "Successfully extracted data for 1 pages and saved to 'output.json'\n",
            "\n",
            "--- SUMMARY OF FIRST PAGE (FOR CONSOLE VERIFICATION) ---\n",
            "Page: 1\n",
            "\n",
            "Dimensions Found (First 5):\n",
            "  Raw: 50', Inches: 600.00, Bbox: [424.24, 82.86, 454.42, 106.02]\n",
            "  Raw: 14', Inches: 168.00, Bbox: [482.08, 227.91, 499.06, 240.94]\n",
            "  Raw: 8' 9, Inches: 105.00, Bbox: [512.81, 227.91, 522.55, 240.94]\n",
            "  Raw: 3\", Inches: 3.00, Bbox: [590.59, 238.11, 602.46, 251.14]\n",
            "  Raw: 10' 3\", Inches: 123.00, Bbox: [616.22, 238.11, 633.2, 251.14]\n",
            "\n",
            "Codes Found:\n",
            "  No cabinet/appliance codes found on this page.\n",
            "----------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}